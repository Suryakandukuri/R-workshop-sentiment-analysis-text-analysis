getwd()
library(XLConnect)
library(xlsx)
install.packages("rJava")
library(xlsx)
library(xlsx)
library(xlsx)
library(tm)
library(tm.plugin.webmining)
x1 <- WebCorpus(GoogleNewsSource("india galaxy j7"))
install.packages("JavaGD")
install.packages("rJava")
library(rJava)
library(rJava)
library(rJava)
library(rJava)
library(tm.plugin.webmining)
library(rJava)
x1 <- WebCorpus(GoogleNewsSource("india galaxy j7"))
library(twitteR)
library(rjson)
library(httr)
library(stringr)
library(ggplot2)
library(RColorBrewer)
library(plyr)
library(bit64)
setup_twitter_oauth("a2WqnFLJxLtehroCRWyLuqvl5", "Dnc8BH3FwDaLJ87KSIZ548CSX2HXtxTS7mkXOzLJYIZK9lDMcm", "3307567015-YuWE96K82q0P4qFOBqhDz1u2kNE0fvFgh0mU4QX","mZPepECiLLA6U7eijStK66iKga1JbEDDOTK4h5oUfcM5T")
pos.words <- scan('HuLiuOpinionLexicon/positive-words.txt', what='character', comment.char=';')
setwd("/Users/suryakandukuri/Documents/RWorkshop")
pos.words <- scan('HuLiuOpinionLexicon/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('HuLiuOpinionLexicon/negative-words.txt', what='character', comment.char=';')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
icici.tweets <- searchTwitter('to:@ICICIBank_Care', n=1000, lang="en")
icici.text = laply(icici.tweets, function(t) t$getText())
icici.text = gsub("[^[:alnum:]|^[:space:]]", "", icici.text)
icici.scores <- score.sentiment(icici.text, pos.words,
neg.words, .progress='text')
View(icici.scores)
icici.scores$team = 'ICICI Bank'
icici.scores$code = 'ICICI'
View(icici.scores)
axis.tweets <- searchTwitter('to:@AxisBankSupport', n=1000, lang="en")
axis.text = laply(axis.tweets, function(t) t$getText())
axis.text = gsub("[^[:alnum:]|^[:space:]]", "", axis.text)
axis.text = gsub("[^[:alnum:]|^[:space:]]", "", axis.text)
axis.scores <- score.sentiment(axis.text, pos.words,
neg.words, .progress='text')
View(axis.scores)
axis.scores$team = 'Axis Bank'
axis.scores$code = 'axis'
sbi.tweets <- searchTwitter('to:@SBICard_Connect', n=1000, lang="en")
sbi.text = laply(sbi.tweets, function(t) t$getText())
sbi.text = gsub("[^[:alnum:]|^[:space:]]", "", sbi.text)
sbi.scores <- score.sentiment(sbi.text, pos.words,
neg.words, .progress='text')
View(sbi.scores)
sbi.scores$team = 'State Bank'
sbi.scores$code = 'sbi'
hdfc.tweets <- searchTwitter('to:@HDFCBank_Cares', n=1000, lang="en")
hdfc.text = laply(hdfc.tweets, function(t) t$getText())
hdfc.text = gsub("[^[:alnum:]|^[:space:]]", "", hdfc.text)
hdfc.scores <- score.sentiment(hdfc.text, pos.words,
neg.words, .progress='text')
View(hdfc.scores)
hdfc.scores$team = 'HDFC Bank'
hdfc.scores$code = 'hdfc'
bank.scores = rbind(icici.scores, axis.scores, sbi.scores, hdfc.scores)
View(bank.scores)
ggplot(data=bank.scores) +
geom_bar(mapping=aes(x=score, fill=team), binwidth=1) +
facet_grid(team~.) +
theme_bw() + scale_color_brewer() +
labs(title="Telco Teams Sentiment")
require("tm")||install.packages("tm")
require("rJava")||install.packages("rJava")
require("wordcloud")||install.packages("wordcloud")
require("textir")||install.packages("textir")
require("RWeka")||install.packages("RWeka")
require("qdap")||install.packages("qdap")
require("maptpx")||install.packages("maptpx")
library("tm")
library("rJava")
library("wordcloud")
library("textir")
library("RWeka")
library("qdap")
library("maptpx")
source("J7_TextFunctions.R")  #    Select text_functions.R
source("/Users/suryakandukuri/Documents/RWorkshop/Product Sentiment Analysis/J7_TextFunctions.R")  #    Select text_functions.R
text  = readLines (file.choose())     # Select txt file you want to analyse
head(text)
Doc.id=seq(1:length(text))            # Assign Document no for each Document
Doc.id=seq(1:length(text))            # Assign Document no for each Document
Doc.id=seq(1:length(text))            # Assign Document no for each Document
calib=data.frame(Doc.id,text)         # Create a dataframe for text documents with document ID
stpw = readLines("j7_stopwords.txt")      # Select stopwords.txt file
stpw = readLines("/Users/suryakandukuri/Documents/RWorkshop/Product Sentiment Analysis/data/j7_stopwords.txt")      # Select stopwords.txt file
stpw1 = stopwords('english')         # tm package stop word list
comn  = unique(c(stpw, stpw1))       # Union of two list
stopwords = unique(c(gsub("'","",comn),comn)) # final stop word lsit after removing punctuation
head (stopwords)
test = text.clean(text)                         # basic HTML Cleaning etc
test  =  removeWords(test,stopwords)            # removing stopwords created above
head(test)                                      # print top documents
clean_text = test
x1 = Corpus(VectorSource(test))          # Create the corpus
dtm1 = custom.dtm(x1,"tf")               # Document Term Frequency
dtm2 = custom.dtm(x1,"tfidf")            # Term Frequency Inverse Document Frequency Scheme
freq1 = (sort(apply(dtm1,2,sum), decreasing =T)) # Calcualte term frequency
freq1[1:80]                                     # View top 80 terms
windows()  # New plot window
wordcloud(names(freq1), freq1, scale=c(8,1),1, max.words=200,colors=brewer.pal(8, "Dark2")) # Plot results in a word cloud
title(sub = "Term Frequency - Wordcloud")
freq2 = (sort(apply(dtm2,2,sum), decreasing =T)) # Calcualte term frequency
freq2[1:80]                                     # View top 80 terms
