setwd("/Users/suryakandukuri/Documents/RWorkshop")
library(twitteR)
library(rjson)
library(httr)
library(stringr)
library(ggplot2)
library(RColorBrewer)
library(plyr)
library(bit64)
setup_twitter_oauth("a2WqnFLJxLtehroCRWyLuqvl5", "Dnc8BH3FwDaLJ87KSIZ548CSX2HXtxTS7mkXOzLJYIZK9lDMcm", "3307567015-YuWE96K82q0P4qFOBqhDz1u2kNE0fvFgh0mU4QX","mZPepECiLLA6U7eijStK66iKga1JbEDDOTK4h5oUfcM5T")
pos.words <- scan('HuLiuOpinionLexicon\\positive-words.txt', what='character', comment.char=';')
pos.words <- scan('HuLiuOpinionLexicon/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('HHuLiuOpinionLexicon/negative-words.txt', what='character', comment.char=';')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
airtel.tweets <- searchTwitter('to:@airtel_presence', n=500, lang="en")
airtel.text = laply(airtel.tweets, function(t) t$getText())
airtel.text = gsub("[^[:alnum:]|^[:space:]]", "", airtel.text)
airtel.scores <- score.sentiment(airtel.text, pos.words,
neg.words, .progress='text')
airtel.scores$team = 'Bharti Airtel'
airtel.scores$code = 'AIRTEL'
neg.words <- scan('HHuLiuOpinionLexicon/negative-words.txt', what='character', comment.char=';')
neg.words <- scan('HuLiuOpinionLexicon/negative-words.txt', what='character', comment.char=';')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
airtel.tweets <- searchTwitter('to:@airtel_presence', n=500, lang="en")
airtel.text = laply(airtel.tweets, function(t) t$getText())
airtel.text = gsub("[^[:alnum:]|^[:space:]]", "", airtel.text)
airtel.scores <- score.sentiment(airtel.text, pos.words,
neg.words, .progress='text')
airtel.scores$team = 'Bharti Airtel'
airtel.scores$code = 'AIRTEL'
View(airtel.scores)
vodafone.tweets <- searchTwitter('to:@vodafonein', n=500, lang="en")
vodafone.text = laply(vodafone.tweets, function(t) t$getText())
vodafone.text = gsub("[^[:alnum:]|^[:space:]]", "", vodafone.text)
vodafone.scores <- score.sentiment(vodafone.text, pos.words,
neg.words, .progress='text')
vodafone.scores$team = 'Vodafone India'
vodafone.scores$code = 'vodafone'
telco.scores = rbind(airtel.scores, vodafone.scores)
ggplot(data=telco.scores) +
geom_histogram(mapping=aes(x=score, fill=team), binwidth=1) +
facet_grid(team~.) +
theme_bw() + scale_color_brewer() +
labs(title="Telco Teams Sentiment")
setwd("/Users/suryakandukuri/Documents/RWorkshop")
library(twitteR)
library(rjson)
library(httr)
library(stringr)
library(ggplot2)
library(RColorBrewer)
library(plyr)
library(bit64)
setup_twitter_oauth("a2WqnFLJxLtehroCRWyLuqvl5", "Dnc8BH3FwDaLJ87KSIZ548CSX2HXtxTS7mkXOzLJYIZK9lDMcm", "3307567015-YuWE96K82q0P4qFOBqhDz1u2kNE0fvFgh0mU4QX","mZPepECiLLA6U7eijStK66iKga1JbEDDOTK4h5oUfcM5T")
pos.words <- scan('HuLiuOpinionLexicon/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('HuLiuOpinionLexicon/negative-words.txt', what='character', comment.char=';')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
icici.tweets <- searchTwitter('to:@ICICIBank_Care', n=100, lang="en")
icici.tweets <- searchTwitter('to:@ICICIBank_Care', n=1000, lang="en")
icici.text = laply(icici.tweets, function(t) t$getText())
icici.text = gsub("[^[:alnum:]|^[:space:]]", "", icici.text)
icici.scores <- score.sentiment(icici.text, pos.words,
neg.words, .progress='text')
icici.scores$team = 'ICICI Bank'
icici.scores$code = 'ICICI'
axis.tweets <- searchTwitter('to:@AxisBankSupport', n=100, lang="en")
axis.tweets <- searchTwitter('to:@AxisBankSupport', n=1000, lang="en")
axis.text = laply(axis.tweets, function(t) t$getText())
axis.text = gsub("[^[:alnum:]|^[:space:]]", "", axis.text)
axis.scores <- score.sentiment(axis.text, pos.words,
neg.words, .progress='text')
axis.scores$team = 'Axis Bank'
axis.scores$code = 'axis'
sbi.tweets <- searchTwitter('to:@SBICard_Connect', n=1000, lang="en")
sbi.text = laply(sbi.tweets, function(t) t$getText())
sbi.text = gsub("[^[:alnum:]|^[:space:]]", "", sbi.text)
sbi.scores <- score.sentiment(sbi.text, pos.words,
neg.words, .progress='text')
sbi.scores$team = 'State Bank'
sbi.scores$code = 'sbi'
hdfc.tweets <- searchTwitter('to:@HDFCBank_Cares', n=1000, lang="en")
hdfc.text = laply(hdfc.tweets, function(t) t$getText())
hdfc.text = gsub("[^[:alnum:]|^[:space:]]", "", hdfc.text)
hdfc.scores <- score.sentiment(hdfc.text, pos.words,
neg.words, .progress='text')
hdfc.scores$team = 'HDFC Bank'
hdfc.scores$code = 'hdfc'
bank.scores = rbind(icici.scores, axis.scores, sbi.scores, hdfc.scores)
ggplot(data=bank.scores) +
geom_bar(mapping=aes(x=score, fill=team), binwidth=1) +
facet_grid(team~.) +
theme_bw() + scale_color_brewer() +
labs(title="Telco Teams Sentiment")
ggplot(data=bank.scores) +
geom_histogram(mapping=aes(x=score, fill=team), binwidth=1) +
facet_grid(team~.) +
theme_bw() + scale_color_brewer() +
labs(title="Telco Teams Sentiment")
require("tm")||install.packages("tm")
require("rJava")||install.packages("rJava")
require("wordcloud")||install.packages("wordcloud")
require("textir")||install.packages("textir")
require("RWeka")||install.packages("RWeka")
require("qdap")||install.packages("qdap")
require("maptpx")||install.packages("maptpx")
library("tm")
library("rJava")
library("wordcloud")
library("textir")
library("RWeka")
library("qdap")
library("maptpx")
setwd("/Users/suryakandukuri/Documents/RWorkshop")
source("J7_Flipkart.R")
setwd("/Users/suryakandukuri/Documents/RWorkshop/Product Sentiment Analysis")
source("J7_Flipkart.R")
source("J7_Twitter.R")
require(stringr)||install.packages("stringr"); library(stringr)
require(utils)||install.packages("utils"); library(utils)
flipkart = function(url,        # Flipkart review URL. first click on show all or top review
n )       # Number of pages to extarct
{
text_page=character(0)   # define blank file
pb <- txtProgressBar(min = 1, max = n, style = 3)    # define progress bar
url = unlist(str_split(url,"&"))[1]
for(i in 0:n){           # loop for url
p =i*10
e = "&rating=1,2,3,4,5&reviewers=all&type=top&sort=most_helpful&start="
url0 = paste(url,e,p,sep="")           # Create flipkart url in correct format
text = readLines(url0)     # Read URL
text_start = grep("<span class=\"review-text\">",text)   # review start marker
text_stop = grep("<div class=\"tpadding10 line feedback-container\">", text)  # review end marker
setTxtProgressBar(pb, i)             # print progress bar
if (length(text_start) == 0) break    # check for loop termination, i.e valid page found
for(j in 1:length(text_start))        # Consolidate all reviews
{
text_temp = paste(paste(text[(text_start[j]+1):(text_stop[j])]),collapse=" ")
text_page = c(text_page,text_temp)
}
#Sys.sleep(1)
}
text_page = gsub("<.*?>", "", text_page)       # regex for Removing HTML character
text_page = gsub("^\\s+|\\s+$", "", text_page) # regex for removing leading and trailing white space
#text_page = gsub("Was this review helpful.*?helpful.","",text_page)
text_page = gsub("&amp","",text_page)
text_page = gsub("&quot","",text_page)
return(text_page)       # return reviews
}
url = "http://www.flipkart.com/samsung-galaxy-j7/product-reviews/ITMEAFBFJHSYDBPW?pid=MOBE93GWSMGZHFSK"
j7_gold= flipkart(url,30)
require(tm)||install.packages("tm")
require(tm.plugin.webmining)||install.packages("tm.plugin.webmining")
library(tm)
library(tm.plugin.webmining)
x1 <- WebCorpus(GoogleNewsSource("india galaxy j7"))
require("base64enc")||install.packages("base64enc")
library(twitteR)
library(base64enc)
api_key <- "fnLKeusO9EbIiQL0k8I5juYW9"                                  #Consumer key
api_secret <- "KchEB4KIEY7wuCtnNKsAbWWqmC7fwFKIbQ6KUd9XXNLGAFzdJ4"      #Consumer secret
access_token <- "3987295005-OPRfxUmGU3TyTcw7l5X4Nrl7ZcRxznhiBRSu7k1"    #Access token
access_token_secret <- "yl7Ob0t8xKxb62KkbCtj8h32LAVjkHUWsUsdyWcs1JrZd"  #Access token secret
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
tweets = searchTwitter('#GalaxyJ7 OR Samsung Galaxy J7 OR Samsung J7 OR #samsunggalaxyj7 OR #samsungj7',n=1000,lang='en')     # hash tag for tweets search and number of tweets
tweets = twListToDF(tweets)    # Convert from list to dataframe
tweets.df = tweets[,1]  # assign tweets for cleaning
tweets.df = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", tweets.df);head(tweets.df)
tweets.df = gsub("@\\w+", "", tweets.df);head(tweets.df) # regex for removing @user
tweets.df = gsub("[[:punct:]]", "", tweets.df);head(tweets.df) # regex for removing punctuation mark
tweets.df = gsub("http\\w+", "", tweets.df);head(tweets.df) # regex for removing links
tweets.df = gsub("\n", " ", tweets.df);head(tweets.df)  ## regex for removing new line (\n)
tweets.df = gsub("[ \t]{2,}", " ", tweets.df);head(tweets.df) ## regex for removing two blank space
tweets.df =  gsub("[^[:alnum:]///' ]", " ", tweets.df)     # keep only alpha numeric
tweets.df =  iconv(tweets.df, "latin1", "ASCII", sub="")   # Keep only ASCII characters
tweets.df = gsub("^\\s+|\\s+$", "", tweets.df);head(tweets.df)  # Remove leading and trailing white space
tweets.df = gsub("GalaxyJ","GalaxyJ7",tweets.df)
tweets.df = gsub("Galaxy J","Galaxy J7",tweets.df)
tweets.df = gsub("Samsung J","Samsung J7",tweets.df)
tweets.df = gsub("galaxyJ","galaxyJ7",tweets.df)
tweets.df = gsub("samsungj","samsungj7",tweets.df)
tweets.df = gsub("amp","",tweets.df)
tweets[,1] = tweets.df # save in Data frame
final_tweets = tweets$text
final_tweets = unique(final_tweets)
write.table(final_tweets,"j7_tweets.txt",row.names=F,col.names=F)
x1 <- WebCorpus(GoogleNewsSource("india galaxy j7"))
require(tm)||install.packages("tm")
require(tm.plugin.webmining)||install.packages("tm.plugin.webmining")
library(tm)
library(tm.plugin.webmining)
x1 <- WebCorpus(GoogleNewsSource("india galaxy j7"))
install.packages("tm.plugin.webmining")
x1 <- WebCorpus(GoogleNewsSource("india galaxy j7"))
library("curl", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("tm.plugin.webmining", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
detach("package:curl", unload=TRUE)
detach("package:tm.plugin.webmining", unload=TRUE)
library("tm.plugin.webmining", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library(rJava)
x1 <- WebCorpus(GoogleNewsSource("india galaxy j7"))
library(tm.plugin.webmining)
library(tm.plugin.webmining)
library(rJava)
setwd("") #set working dir
library("tm")
library("rJava")
library("wordcloud")
library("textir")
library("RWeka")
library("qdap")
library("maptpx")
library("rJava")
